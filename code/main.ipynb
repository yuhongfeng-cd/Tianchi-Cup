{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得特征\n",
    "def get_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        X = f.read().split('\\n')\n",
    "        X = X[:-1]\n",
    "        X_npy = np.ones([len(X), 10])\n",
    "        for i, x in enumerate(X): # 遍历每一行\n",
    "            for j, h in enumerate(x.split()[1:]): # 遍历每一行中每一列\n",
    "                X_npy[i][j] = float(h)\n",
    "    return X_npy\n",
    "\n",
    "# 获得标签\n",
    "def get_label(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        y = f.read().split('\\n')\n",
    "        y = y[:-1]\n",
    "        y_npy = np.ones([len(y), ])\n",
    "        for i, y_i in enumerate(y): # 遍历每一行\n",
    "            y_npy[i] = int(y_i.split()[1])\n",
    "    return y_npy\n",
    "\n",
    "# 读取数据\n",
    "train_file = '../data/trainset/train_para_input.txt'\n",
    "train_label_file = '../data/trainset/train_output.txt'\n",
    "test_file = '../data/testset/test_para_input.txt'\n",
    "X_train = get_data(train_file)\n",
    "y_train = get_label(train_label_file)\n",
    "X_test = get_data(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值填充\n",
    "def fill_data_mean(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# 中位值填充\n",
    "def fill_data_median(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# 众数填充\n",
    "def fill_data_most(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# 取零填充\n",
    "def fill_data_zero(X_train, X_test):\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# KNN 缺失值填充\n",
    "def fill_data_knn(X_train, X_test):\n",
    "    imputer = KNNImputer()\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# 缺失值填充\n",
    "X_train_mean, X_test_mean = fill_data_mean(X_train, X_test)\n",
    "X_train_median, X_test_median = fill_data_median(X_train, X_test)\n",
    "X_train_most, X_test_most = fill_data_most(X_train, X_test) \n",
    "X_train_zero, X_test_zero = fill_data_zero(X_train, X_test)\n",
    "X_train_knn, X_test_knn = fill_data_knn(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练及评价\n",
    "def lr_cf(X, y):\n",
    "    # 拆分数据集\n",
    "    # train_size = int(X.shape[0]*0.8)\n",
    "    # X_train = X[:train_size]\n",
    "    # X_test = X[train_size:]\n",
    "    # y_train = y[:train_size]\n",
    "    # y_test = y[train_size:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=99, shuffle=True)\n",
    "    # 模型训练\n",
    "    lr = LogisticRegression(random_state=0)\n",
    "    lr.fit(X_train, y_train)\n",
    "    pre = lr.predict(X_test)\n",
    "    # 模型评估\n",
    "    matrix = confusion_matrix(y_test, pre)\n",
    "    H = matrix[0][0]\n",
    "    M = matrix[0][1]\n",
    "    F = matrix[1][0]\n",
    "    CN = matrix[1][1]\n",
    "    recall = H / (H + M)\n",
    "    precision = H / (H + F)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Develop\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9755930167717584"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_cf(X_train_mean, y_train)\n",
    "# lr_cf(X_train_median, y_train)\n",
    "lr_cf(X_train_most, y_train)\n",
    "# lr_cf(X_train_zero, y_train)\n",
    "# lr_cf(X_train_knn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0259500e+02, 1.7007400e+22, 3.5754500e+12, ..., 2.6258710e+03,\n",
       "        0.0000000e+00, 8.0000000e-01],\n",
       "       [2.2351300e+02, 1.7071700e+22, 3.8818400e+12, ..., 2.7945070e+03,\n",
       "        0.0000000e+00, 1.0000000e+00],\n",
       "       [2.4694300e+02, 1.8685100e+22, 4.3308300e+12, ..., 2.8527170e+03,\n",
       "        1.9380000e+00, 1.8860000e+00],\n",
       "       ...,\n",
       "       [2.2886500e+03, 6.9717800e+23, 5.4900200e+13, ..., 9.5006100e+03,\n",
       "        4.3770000e+00, 3.7198002e+01],\n",
       "       [2.4291280e+03, 7.1156800e+23, 5.9208500e+13, ..., 9.1546160e+03,\n",
       "        4.4280000e+00, 3.7312000e+01],\n",
       "       [2.4601400e+03, 7.1565900e+23, 5.9642400e+13, ..., 9.1641970e+03,\n",
       "        4.5040000e+00, 3.6699001e+01]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
